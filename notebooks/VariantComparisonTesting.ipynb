{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af01593-babf-48b2-8a12-9bd70282109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, zipfile, csv\n",
    "import requests\n",
    "import psycopg2\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "from collections import defaultdict\n",
    "from datetime import time\n",
    "\n",
    "from sqlalchemy import URL, create_engine, text\n",
    "from trino.auth import OAuth2Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ae0f7e-08f2-4c1b-9ddc-d9eb8f896df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in parent directories to sys.path to get multiHook library\n",
    "current_dir = os.getcwd()\n",
    "for x in range(4):  # Look four levels up\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "    if parent_dir not in sys.path:\n",
    "        sys.path.append(parent_dir)\n",
    "    current_dir = parent_dir\n",
    "\n",
    "import multihook.pycnxn.dbhook as dbhook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb6ab1a-db80-479f-8738-b31bb32a9338",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def import_bundle(\n",
    "    bundle,\n",
    "    import_trips=True,\n",
    "    import_shapes=True,\n",
    "    import_stops=True,\n",
    "    import_stoptimes=True,\n",
    "    import_calendar=True,\n",
    "    import_calendar_dates=True,\n",
    "    import_routes=True,\n",
    "    cache_bundle=False,\n",
    "):\n",
    "    \"\"\"Import GTFS data from the following tables in ADLS:\n",
    "    - core.dbo.fact_gtfs_trips\n",
    "    - core.dbo.fact_gtfs_shapes\n",
    "    - core.dbo.fact_gtfs_stops\n",
    "    - core.dbo.fact_gtfs_shape_reference\n",
    "    - core.dbo.fact_gtfs_stop_times\n",
    "\n",
    "    - ADD IN CALENDAR, CALENDAR DATES, AND ROUTES\n",
    "    \"\"\"\n",
    "\n",
    "    # GTFS bundle can take some time to import. If there is already a cached GTFS bundle pickle file in the repository, read in that data instead\n",
    "    picklefile = bundle + \".pickle\"\n",
    "    if os.path.isfile(picklefile) == True:\n",
    "        with open(picklefile, \"rb\") as handle:\n",
    "            gtfs_bundle = pickle.load(handle)\n",
    "            return gtfs_bundle\n",
    "\n",
    "    con = create_engine(\n",
    "        r\"trino://trino-route-trino.apps.mtasiprod.eastus.aroapp.io:443/mtadatalake\",\n",
    "        connect_args={\n",
    "            \"auth\": OAuth2Authentication(),\n",
    "            \"http_scheme\": \"https\",\n",
    "        }\n",
    "    )\n",
    "    cur = con.connect()\n",
    "    \n",
    "    output = {}\n",
    "    # Import trips\n",
    "    trip_sql = f\"\"\"\n",
    "    with agency as ( -- get agency id for each route\n",
    "        select distinct route_id, agency_id from mtadatalake.core.fact_gtfs_routes \n",
    "        where bundle = '{bundle}'\n",
    "        )\n",
    "    SELECT trips.route_id ,trip_id, service_id,trip_headsign,direction_id,block_id,shape_id,boarding_type,bundle, agency.agency_id\n",
    "    FROM mtadatalake.core.fact_gtfs_trips trips\n",
    "    join agency on trips.route_id = agency.route_id\n",
    "    where trips.bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_trips == True:\n",
    "        print('Loading trips')\n",
    "        f = cur.execute(text(trip_sql))\n",
    "        trips_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"trips\"] = trips_df\n",
    "\n",
    "    # Import shapes\n",
    "    shape_sql = f\"\"\"\n",
    "    SELECT shape_id, shape_pt_sequence, shape_pt_lat, shape_pt_lon, bundle\n",
    "    FROM mtadatalake.core.fact_gtfs_shapes\n",
    "    where bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_shapes == True:\n",
    "        print(\"Loading shapes\")\n",
    "        f = cur.execute(text(shape_sql))\n",
    "        shapes_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"shapes\"] = shapes_df\n",
    "\n",
    "    # Import stops\n",
    "    stop_sql = f\"\"\"\n",
    "    SELECT fact_gtfs_stops.stop_id, stop_name, stop_lat, stop_lon, shape_ref.revenue_stop, bundle\n",
    "    FROM mtadatalake.core.fact_gtfs_stops\n",
    "    left join (\n",
    "        SELECT stop_id, MAX(revenue_stop) AS revenue_stop\n",
    "        FROM mtadatalake.core.fact_gtfs_shape_reference\n",
    "        where bundle = '{bundle}'\n",
    "        GROUP BY stop_id\n",
    "    ) shape_ref\n",
    "    on fact_gtfs_stops.stop_id = shape_ref.stop_id\n",
    "    where bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_stops == True:\n",
    "        print(\"Loading stops\")\n",
    "        f = cur.execute(text(stop_sql))\n",
    "        stops_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"stops\"] = stops_df\n",
    "\n",
    "    # Import stop_times\n",
    "    stoptime_sql = f\"\"\"\n",
    "    SELECT trip_id, stop_id, arrival_time, departure_time, timepoint, stop_sequence, pickup_type, drop_off_type, bundle\n",
    "    FROM mtadatalake.core.fact_gtfs_stop_times\n",
    "    where bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_stoptimes == True:\n",
    "        print(\"Loading stop times\")\n",
    "        f = cur.execute(text(stoptime_sql))\n",
    "        stoptimes_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"stoptimes\"] = stoptimes_df\n",
    "\n",
    "    # import calendar\n",
    "    calendar_sql = f\"\"\" \n",
    "    SELECT service_id, monday, tuesday, wednesday, thursday, friday, saturday, sunday, start_date, end_date, bundle, modified_time, loaded_time\n",
    "    FROM mtadatalake.core.fact_gtfs_calendar\n",
    "    where bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_calendar == True:\n",
    "        print(\"Loading calendar\")\n",
    "        f = cur.execute(text(calendar_sql))\n",
    "        calendar_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"calendar\"] = calendar_df\n",
    "\n",
    "    #import calendar_dates\n",
    "    calendar_dates_sql = f\"\"\"\n",
    "    SELECT service_id, \"date\", exception_type\n",
    "    FROM mtadatalake.core.fact_gtfs_calendar_dates\n",
    "    where bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_calendar_dates == True:\n",
    "        print(\"Loading calendar_dates\")\n",
    "        f = cur.execute(text(calendar_dates_sql))\n",
    "        calendar_dates_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"calendar_dates\"] = calendar_dates_df\n",
    "\n",
    "    #import routes\n",
    "    routes_sql = f\"\"\"\n",
    "    SELECT route_id, route_short_name, route_long_name\n",
    "    FROM mtadatalake.core.fact_gtfs_routes\n",
    "    where bundle = '{bundle}'\n",
    "    \"\"\"\n",
    "    if import_calendar_dates == True:\n",
    "        print(\"Loading routes\")\n",
    "        f = cur.execute(text(routes_sql))\n",
    "        routes_df = pd.DataFrame(f.fetchall())\n",
    "        output[\"routes\"] = routes_df\n",
    "\n",
    "    \n",
    "    if cache_bundle == True:\n",
    "        with open(picklefile, \"wb\") as handle:\n",
    "            pickle.dump(output, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"GTFS data for {bundle} successfully loaded and cached\")\n",
    "    else:\n",
    "       print(f\"GTFS data for {bundle} successfully loaded\") \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3dee5f-b46e-453e-a26e-bbeb6ec41e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Instead of having a variant class that generates a schedule each time, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540d26d-03e2-49b2-abb0-aafb1564ff99",
   "metadata": {},
   "source": [
    "### Variant class with metrics as attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e389b2-92d9-400b-a2ab-21a50a4c71bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7728c9be-8b40-4940-94bb-f75096860bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variant:\n",
    "    def __init__(self, shape_id, bundle):\n",
    "        self.shape_id = shape_id\n",
    "        self.bundle = bundle\n",
    "\n",
    "        ### GTFS \n",
    "        self.stops = self.bundle['stops']\n",
    "        self.stop_times = self.bundle['stoptimes']\n",
    "        self.trips = self.bundle['trips']\n",
    "        self.calendar = self.bundle['calendar']\n",
    "        self.calendar_dates = self.bundle['calendar_dates']\n",
    "        \n",
    "        \n",
    "\n",
    "        ### Metrics\n",
    "        self.trip_count = self._get_trip_count()\n",
    "        if self.trip_count == 0: # to filter out variants with no trips later\n",
    "            raise ValueError\n",
    "        self.stop_set = self._get_stop_set()\n",
    "        self.stop_count = self._get_stop_count()\n",
    "        self.headsign = self._get_headsign()\n",
    "        self.startend = self._get_start_end_stops()\n",
    "        self.geometry = self._get_geometry()\n",
    "        self.length = self._get_shape_length()\n",
    "        self.direction = self._get_direction()\n",
    "        self.daytype = self._get_daytype()\n",
    "        self.school = self._get_runs_only_during_school_hours()\n",
    "\n",
    "    ### Metric 1 Getter ### \n",
    "    def _get_trip_count(self):\n",
    "        return self.trips[self.trips['shape_id'] == self.shape_id].shape[0]\n",
    "\n",
    "    ### Metric 2 Getter ### \n",
    "    def _get_stop_set(self):\n",
    "        # Create mapping: trip_id → shape_id\n",
    "        trip_to_shape = self.trips.set_index('trip_id')['shape_id'].to_dict()\n",
    "    \n",
    "        # Find first trip_id for this shape_id\n",
    "        shape_to_trip = {}\n",
    "        for trip_id, shape_id in trip_to_shape.items():\n",
    "            if shape_id not in shape_to_trip:\n",
    "                shape_to_trip[shape_id] = trip_id\n",
    "    \n",
    "        shape_id = self.shape_id\n",
    "        if shape_id not in shape_to_trip:\n",
    "            return []\n",
    "    \n",
    "        trip_id = shape_to_trip[shape_id]\n",
    "    \n",
    "        # Get stop_times for this trip\n",
    "        grouped = self.stop_times.groupby('trip_id')\n",
    "        if trip_id not in grouped.groups:\n",
    "            return []\n",
    "    \n",
    "        trip_stops = grouped.get_group(trip_id).sort_values('stop_sequence')\n",
    "        if trip_stops.empty:\n",
    "            return []\n",
    "    \n",
    "        # Map stop_id → stop_name\n",
    "        stop_id_to_name = self.stops.set_index('stop_id')['stop_name'].to_dict()\n",
    "    \n",
    "        # Ordered list of stop names\n",
    "        ordered_stop_names = [\n",
    "            stop_id_to_name.get(row['stop_id'], row['stop_id'])\n",
    "            for _, row in trip_stops.iterrows()\n",
    "        ]\n",
    "        return ordered_stop_names\n",
    "\n",
    "    ### Metric 3 ###\n",
    "    def _get_stop_count(self):\n",
    "        return len(self._get_stop_set())\n",
    "\n",
    "        \n",
    "    ### Metric 4 Getter ###\n",
    "    def _get_headsign(self):\n",
    "        headsign_map = self.trips[['shape_id', 'trip_headsign']].drop_duplicates(subset='shape_id')\n",
    "        headsign_dict = dict(zip(headsign_map['shape_id'], headsign_map['trip_headsign']))\n",
    "        return headsign_dict.get(self.shape_id, None)\n",
    "    \n",
    "    ### Metric 5 Getter ### \n",
    "    def _get_start_end_stops(self):\n",
    "        stop_names = self._get_stop_set()\n",
    "        if not stop_names:\n",
    "            return (None, None)\n",
    "        return (stop_names[0], stop_names[-1])\n",
    "        \n",
    "    ### Metric 6: Geometry Getter ###\n",
    "    def _get_geometry(self):\n",
    "        # Filter trips for this shape\n",
    "        relevant_trips = self.trips[self.trips['shape_id'] == self.shape_id]\n",
    "        if relevant_trips.empty:\n",
    "            return None\n",
    "    \n",
    "        # Get stop_times for first trip in shape\n",
    "        relevant_stop_times = self.stop_times[self.stop_times['trip_id'].isin(relevant_trips['trip_id'])]\n",
    "        first_trip_id = relevant_trips.iloc[0]['trip_id']\n",
    "        trip_stop_times = relevant_stop_times[relevant_stop_times['trip_id'] == first_trip_id]\n",
    "        trip_stop_times = trip_stop_times.sort_values(by='stop_sequence')\n",
    "    \n",
    "        # Merge with stops to get coordinates\n",
    "        stops_with_coords = trip_stop_times.merge(self.stops, on='stop_id', how='left')\n",
    "        if stops_with_coords[['stop_lat', 'stop_lon']].isnull().any().any():\n",
    "            return None  # Missing coordinate data\n",
    "    \n",
    "        # Create LineString\n",
    "        return LineString(zip(stops_with_coords['stop_lon'], stops_with_coords['stop_lat']))\n",
    "\n",
    "    ### Metric 7 Getter ###\n",
    "    def _get_shape_length(self):\n",
    "        geom = self._get_geometry()\n",
    "        if geom is None:\n",
    "            return np.nan\n",
    "    \n",
    "        geo_line = gpd.GeoSeries([geom], crs=\"EPSG:4326\").to_crs(\"EPSG:2263\")\n",
    "        return geo_line.length.iloc[0]\n",
    "\n",
    "        \n",
    "    ### Metric 8 ### \n",
    "    def _get_direction(self):\n",
    "        directions = self.trips[self.trips['shape_id'] == self.shape_id]['direction_id'].drop_duplicates()\n",
    "        if directions.empty:\n",
    "            return None\n",
    "        return directions.iloc[0]\n",
    "\n",
    "\n",
    "    ### Metric 9 ### \n",
    "    def _get_daytype(self):\n",
    "        shape_trips = self.trips[self.trips['shape_id'] == self.shape_id]\n",
    "        service_ids = shape_trips['service_id'].unique()\n",
    "        service_days = self.calendar[self.calendar['service_id'].isin(service_ids)]\n",
    "    \n",
    "        # List of day columns\n",
    "        day_columns = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "    \n",
    "        # Sum across all service_ids to find which daytypes are served\n",
    "        active_days = (service_days[day_columns].sum() > 0)\n",
    "    \n",
    "        # Get list of active day names\n",
    "        active_day_names = active_days[active_days].index.tolist()\n",
    "    \n",
    "        # Decide daytype based on active days\n",
    "        weekdays = {'monday', 'tuesday', 'wednesday', 'thursday', 'friday'}\n",
    "        weekends = {'saturday', 'sunday'}\n",
    "    \n",
    "        active_day_set = set(active_day_names)\n",
    "    \n",
    "        if active_day_set.issubset(weekdays):\n",
    "            return 'weekday'\n",
    "        elif active_day_set.issubset(weekends):\n",
    "            return 'weekend'\n",
    "        else:\n",
    "            return 'weekday'\n",
    "            \n",
    "    ### Metric 10 ### \n",
    "    def _get_runs_only_during_school_hours(self):\n",
    "        morning_start = time(7, 0)\n",
    "        morning_end = time(9, 0)\n",
    "        afternoon_start = time(14, 0)\n",
    "        afternoon_end = time(16, 0)\n",
    "    \n",
    "        variant_trips = self.trips[self.trips['shape_id'] == self.shape_id]\n",
    "    \n",
    "        if variant_trips.empty:\n",
    "            return False\n",
    "    \n",
    "        first_stop_times = (\n",
    "            self.stop_times[\n",
    "                (self.stop_times['trip_id'].isin(variant_trips['trip_id'])) &\n",
    "                (self.stop_times['stop_sequence'] == 1)\n",
    "            ][['trip_id', 'departure_time']]\n",
    "        )\n",
    "    \n",
    "        def parse_time(t_str):\n",
    "            h, m, s = map(int, t_str.split(':'))\n",
    "            h = h % 24  # Normalize 24+ hour times\n",
    "            return time(h, m, s)\n",
    "    \n",
    "        first_stop_times['dep_time_obj'] = first_stop_times['departure_time'].apply(parse_time)\n",
    "    \n",
    "        def in_school_hours(t):\n",
    "            return (morning_start <= t <= morning_end) or (afternoon_start <= t <= afternoon_end)\n",
    "    \n",
    "        # Check if ALL trips are within school hours\n",
    "        all_in_school = first_stop_times['dep_time_obj'].apply(in_school_hours).all()\n",
    "    \n",
    "        return all_in_school\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ca1b51-9cac-47eb-858f-c2ec683f31fb",
   "metadata": {},
   "source": [
    "# Variant List\n",
    "#### Create a list of all variants for all routes of any bundle. Eventually will compare variants of one bundle to variants of another. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e57398-29d4-4bb3-9be4-db8df68b96a8",
   "metadata": {},
   "source": [
    "## Step 1: Loading in Bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bcec87-2517-4208-9a3a-20003e6a68f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trips\n",
      "Loading shapes\n",
      "Loading stops\n",
      "Loading stop times\n",
      "Loading calendar\n",
      "Loading calendar_dates\n",
      "Loading routes\n",
      "GTFS data for 2024Jan_Prod_r01_b03_Predate_Shuttles_v2_i1_scheduled successfully loaded\n",
      "Loading trips\n",
      "Loading shapes\n",
      "Loading stops\n",
      "Loading stop times\n",
      "Loading calendar\n",
      "Loading calendar_dates\n",
      "Loading routes\n",
      "GTFS data for 2024April_Prod_r01_b07_Predate_02_Shuttles_2_SCHEDULED successfully loaded\n"
     ]
    }
   ],
   "source": [
    "bundle_names = [\n",
    "    '2024Jan_Prod_r01_b03_Predate_Shuttles_v2_i1_scheduled',\n",
    "    '2024April_Prod_r01_b07_Predate_02_Shuttles_2_SCHEDULED'\n",
    "]\n",
    "bundle_dfs = [import_bundle(name) for name in bundle_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6a1b3-2e77-4580-9c64-8b1dd7d9e697",
   "metadata": {},
   "source": [
    "#### Step 1a: Filter to most representative days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3061e65-2977-4724-bfcb-b7f9d55b5901",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Takes in a bundle dictionary, along with the dates and days of week you'd like to filter to,\n",
    "### and returns the filtered dataframes as the new bundle dict\n",
    "def bundlefilter(bundle, target_dates, days_of_week):\n",
    "    trips = bundle['trips']\n",
    "    calendar = bundle['calendar']\n",
    "    calendar_dates = bundle['calendar_dates']\n",
    "    routes = bundle['routes']\n",
    "\n",
    "    filtered_trips = pd.DataFrame()\n",
    "\n",
    "    for date, day in zip(target_dates, days_of_week):\n",
    "        # Base services active on the day\n",
    "        base_services = calendar[\n",
    "            (calendar[day] == 1) &\n",
    "            (calendar['start_date'] <= date) &\n",
    "            (calendar['end_date'] >= date)\n",
    "        ]['service_id']\n",
    "\n",
    "        # Exceptions on that date\n",
    "        exceptions = calendar_dates[calendar_dates['date'] == date]\n",
    "        removed = exceptions[exceptions['exception_type'] == 2]['service_id']\n",
    "        added = exceptions[exceptions['exception_type'] == 1]['service_id']\n",
    "\n",
    "        # Apply exception logic\n",
    "        final_services = pd.concat([\n",
    "            base_services[~base_services.isin(removed)],\n",
    "            added\n",
    "        ]).drop_duplicates()\n",
    "\n",
    "        # Filter trips for this date\n",
    "        trips_today = trips[trips['service_id'].isin(final_services)]\n",
    "        filtered_trips = pd.concat([filtered_trips, trips_today])\n",
    "\n",
    "    # Remove duplicates\n",
    "    filtered_trips = filtered_trips.drop_duplicates()\n",
    "\n",
    "    # Filter stop_times to match trips\n",
    "    stop_times = bundle['stoptimes']\n",
    "    filtered_stop_times = stop_times[stop_times['trip_id'].isin(filtered_trips['trip_id'])]\n",
    "\n",
    "    # Return a new filtered bundle\n",
    "    return {\n",
    "        'trips': filtered_trips.reset_index(drop=True),\n",
    "        'stoptimes': filtered_stop_times.reset_index(drop=True),\n",
    "        'stops': bundle['stops'], \n",
    "        'shapes': bundle['shapes'],  \n",
    "        'calendar': calendar,\n",
    "        'calendar_dates': calendar_dates,\n",
    "        'routes': routes\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f468f6d7-42bc-4f5a-89e9-dde8669caf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle1 = bundlefilter(bundle_dfs[0],\n",
    "                                target_dates=[20240108, 20240113, 20240107],\n",
    "                                days_of_week=['monday', 'saturday', 'sunday'])\n",
    "\n",
    "bundle2 = bundlefilter(bundle_dfs[1],\n",
    "                                target_dates=[20240402, 20240406, 20240407],\n",
    "                                days_of_week=['tuesday', 'saturday', 'sunday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198cef3f-25bb-40e9-9170-a9c3c1fde3d3",
   "metadata": {},
   "source": [
    "##### Comparisons v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de89042d-adc4-49ef-bc44-094b5ffabdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_variants(trips, route_id):\n",
    "    shape_ids = trips[trips['route_id'] == route_id]['shape_id'].dropna().unique()\n",
    "    return list(shape_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686ec5cf-cb74-46b9-8521-423b6c917ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q370222', 'Q370223', 'Q370221', 'Q370220', 'Q370158']\n",
      "['Q54O0031', 'Q54O0030', 'Q54O0032', 'Q54O0257', 'Q54O0259', 'Q54O0255', 'Q54O0258', 'Q54O0252', 'Q54O0262', 'Q540054', 'Q540035', 'Q540227', 'Q540051', 'Q540055', 'Q540050']\n",
      "['Q100593', 'Q100580', 'Q100521', 'Q100523', 'Q100577', 'Q100578', 'Q100594', 'Q100529']\n"
     ]
    }
   ],
   "source": [
    "q37_variants_bundle1 = find_variants(bundle1['trips'], 'Q37')\n",
    "print(q37_variants_bundle1)\n",
    "q54_variants_bundle1 = find_variants(bundle1['trips'], 'Q54')\n",
    "print(q54_variants_bundle1)\n",
    "q10_variants_bundle1 = find_variants(bundle1['trips'], 'Q10')\n",
    "print(q10_variants_bundle1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fca1490-4f28-44df-a561-697b5bb101bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q370222', 'Q370223', 'Q370221', 'Q370220', 'Q370158']\n",
      "['Q54O0255', 'Q54O0031', 'Q54O0030', 'Q54O0032', 'Q54O0252', 'Q54O0259', 'Q54O0262', 'Q54O0258', 'Q54O0257', 'Q540227', 'Q540035', 'Q540054', 'Q540051', 'Q540055', 'Q540050']\n",
      "['Q100578', 'Q100593', 'Q100577', 'Q100580', 'Q100594', 'Q100521', 'Q100529', 'Q100523']\n"
     ]
    }
   ],
   "source": [
    "q37_variants_bundle2 = find_variants(bundle2['trips'], 'Q37')\n",
    "print(q37_variants_bundle2)\n",
    "q54_variants_bundle2 = find_variants(bundle2['trips'], 'Q54')\n",
    "print(q54_variants_bundle2)\n",
    "q10_variants_bundle2 = find_variants(bundle2['trips'], 'Q10')\n",
    "print(q10_variants_bundle2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d047b-e3d3-4769-bcf0-50ed17f3be29",
   "metadata": {},
   "source": [
    "#### Creating variant objects, average loading time of 1 minute per route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63269197-3f8e-44cd-983d-3c9f93bd8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants1 = {}\n",
    "for shape in q37_variants_bundle1:\n",
    "    try:\n",
    "        v = Variant(shape, bundle1)\n",
    "        variants1[shape] = v\n",
    "    except ValueError:\n",
    "        # Skip shapes with zero trips\n",
    "        continue\n",
    "variants2 = {}\n",
    "for shape in q54_variants_bundle1:\n",
    "    try:\n",
    "        v = Variant(shape, bundle1)\n",
    "        variants2[shape] = v\n",
    "    except ValueError:\n",
    "        # Skip shapes with zero trips\n",
    "        continue\n",
    "variants3 = {}\n",
    "for shape in q10_variants_bundle1:\n",
    "    try:\n",
    "        v = Variant(shape, bundle1)\n",
    "        variants3[shape] = v\n",
    "    except ValueError:\n",
    "        # Skip shapes with zero trips\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bea872e1-a2c8-48b4-b5a0-e27c07d27af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants1b = {}\n",
    "for shape in q37_variants_bundle2:\n",
    "    try:\n",
    "        v = Variant(shape, bundle2)\n",
    "        variants1b[shape] = v\n",
    "    except ValueError:\n",
    "        # Skip shapes with zero trips\n",
    "        continue\n",
    "variants2b = {}\n",
    "for shape in q54_variants_bundle2:\n",
    "    try:\n",
    "        v = Variant(shape, bundle2)\n",
    "        variants2b[shape] = v\n",
    "    except ValueError:\n",
    "        # Skip shapes with zero trips\n",
    "        continue\n",
    "variants3b = {}\n",
    "for shape in q10_variants_bundle2:\n",
    "    try:\n",
    "        v = Variant(shape, bundle2)\n",
    "        variants3b[shape] = v\n",
    "    except ValueError:\n",
    "        # Skip shapes with zero trips\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0113fe-888f-44c7-bdf6-5070d5664c99",
   "metadata": {},
   "source": [
    "#### Output: Variant List with inferred Variant Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff94d86d-f972-4c62-bb5d-a7036defb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_variants(variants):\n",
    "    group = defaultdict(list)\n",
    "    for v in variants.values():  \n",
    "        # Create a single string key for easy reading\n",
    "        key = f\"{v.daytype}_{v.direction}\"\n",
    "        group[key].append(v)\n",
    "    return group\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5cf9b49-b324-4bb1-90ca-302007fc3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_variant(variants):\n",
    "    trip_weight = 0.6\n",
    "    length_weight = 0.3\n",
    "    stop_weight = 0.1\n",
    "\n",
    "    def score(v):\n",
    "        length = v.length if v.length is not None else 0\n",
    "        return (trip_weight * v.trip_count) + (length_weight * length / 1000) + (stop_weight * v.stop_count)\n",
    "\n",
    "    return max(variants, key=score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "641c4eaa-4adc-4c5e-8f47-a49edb319ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Takes in a variant and its corresponding 'main' variant to compare it to\n",
    "### returns its inferred variant type\n",
    "def inferred_variant_type(variant, main):\n",
    "    if variant.shape_id == main.shape_id:\n",
    "        return \"main\"\n",
    "    elif variant.trip_count <= 2: ## If only 1 or 2 trips, classify as other.\n",
    "        return \"other/unknown\"\n",
    "    elif ((main.stop_count - variant.stop_count)/main.stop_count > 0.4) or any(word in variant.headsign.lower() for word in (\"limited\",\"ltd\")): \n",
    "        ## if 'limited' or 'express' in headsign, or if both stop count is at least 40 percent smaller than main\n",
    "        return \"limited\"\n",
    "    elif (variant.daytype == 'weekday') and (variant.school == True):\n",
    "        ## if on weekdays and durings school hours\n",
    "        return \"school\"\n",
    "    elif ((main.stop_count - variant.stop_count)/main.stop_count) > 0.15 and ((main.length - variant.length)/main.length) > 0.15:\n",
    "        ## if both stop count and length are more than 15 percent shorter/smaller than main\n",
    "        return \"short\"\n",
    "    else:\n",
    "        return \"branch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "821621ce-0442-48dd-9b6f-48527274273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_variant_table(variants):\n",
    "    grouped = group_variants(variants)\n",
    "    rows = []\n",
    "    \n",
    "    for group_key, group in grouped.items():\n",
    "        main_variant = find_main_variant(group)\n",
    "        for v in group:\n",
    "            variant_type = inferred_variant_type(v, main_variant)\n",
    "            rows.append({\n",
    "                \"shape_id\": v.shape_id,\n",
    "                \"daytype_direction\": group_key,\n",
    "                \"trip_count\": v.trip_count,\n",
    "                \"stop_count\": v.stop_count,\n",
    "                \"length\": v.length,\n",
    "                \"headsign\": v.headsign,\n",
    "                \"start_end_stops\": v.startend,\n",
    "                \"inferred_variant_type\": variant_type\n",
    "            })\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4806ac5-1a64-4c38-9966-9ea635e262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all3 = {'q37':variants1,'q54':variants2,'q10':variants3}\n",
    "all3b = {'q37':variants1b,'q54':variants2b,'q10':variants3b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cd1d498-2d3f-4773-9681-a097d4d22b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_routes_variant_table(all_variants_dict):\n",
    "    dfs = []\n",
    "    for route_id, variants_dict in all_variants_dict.items():\n",
    "        df = build_variant_table(variants_dict) \n",
    "        df['route_id'] = route_id  # add route id column\n",
    "        dfs.append(df)\n",
    "    all_variants_df = pd.concat(dfs, ignore_index=True)\n",
    "    return all_variants_df\n",
    "final = build_all_routes_variant_table(all3)\n",
    "final.to_excel('test.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf830fe3-0353-48b2-883d-02a62bcfb586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a5bb38-5b98-424e-84c8-4787ed9e1887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers: similarity metrics\n",
    "def stop_set_similarity(s1, s2):\n",
    "    if not s1 and not s2:\n",
    "        return 1.0\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "    inter = len(s1 & s2)\n",
    "    union = len(s1 | s2)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def shape_similarity(sh1, sh2):\n",
    "    if sh1 is None or sh2 is None:\n",
    "        return 0.0\n",
    "\n",
    "    # Ensure both are shapely geometries\n",
    "    if not hasattr(sh1, 'intersection'):\n",
    "        sh1 = LineString(sh1)\n",
    "    if not hasattr(sh2, 'intersection'):\n",
    "        sh2 = LineString(sh2)\n",
    "\n",
    "    # Use intersection length vs union length\n",
    "    inter_length = sh1.intersection(sh2).length\n",
    "    union_geom = unary_union([sh1, sh2])\n",
    "    union_length = union_geom.length\n",
    "\n",
    "    return inter_length / union_length if union_length else 0.0\n",
    "    \n",
    "def start_end_match(a, b):\n",
    "    return 1.0 if (a and b and a[0] == b[0] and a[1] == b[1]) else 0.0\n",
    "\n",
    "def headsign_match(a, b):\n",
    "    if a is None or b is None:\n",
    "        return 0.0\n",
    "    return 1.0 if a.strip().lower() == b.strip().lower() else 0.0\n",
    "\n",
    "def ratio_score(a, b):\n",
    "    # returns value in [0,1] closeness of ratio to 1\n",
    "    if a is None or b is None or (a == 0 and b == 0):\n",
    "        return 0.0\n",
    "    r = min(a,b) / max(a,b) if max(a,b) else 0.0\n",
    "    return r\n",
    "\n",
    "# composite similarity (weights can be changed)\n",
    "def variant_similarity(v1, v2, weights=None):\n",
    "    if weights is None:\n",
    "        weights = {\n",
    "            'stop_set_similarity': 0.15,\n",
    "            'shape_similarity': 0.20,\n",
    "            'startend': 0.20,\n",
    "            'headsign': 0.10,\n",
    "            'trip_ratio': 0.10,\n",
    "            'length_ratio': 0.15,\n",
    "            'stopcount_ratio': 0.10\n",
    "        }\n",
    "    sc = {}\n",
    "    sc['stop_set_similarity'] = stop_set_similarity(v1['stop_id_set'], v2['stop_id_set'])\n",
    "    sc['shape_similarity'] = shape_similarity(v1.get('geometry'), v2.get('geometry'))\n",
    "    sc['startend'] = start_end_match(v1.get('startend'), v2.get('startend'))\n",
    "    sc['headsign'] = headsign_match(v1.get('headsign'), v2.get('headsign'))\n",
    "    sc['trip_ratio'] = ratio_score(v1.get('trip_count',0), v2.get('trip_count',0))\n",
    "    sc['length_ratio'] = ratio_score(v1.get('length',0), v2.get('length',0))\n",
    "    sc['stopcount_ratio'] = ratio_score(v1.get('stop_count',0), v2.get('stop_count',0))\n",
    "\n",
    "    total = 0.0\n",
    "    for k,w in weights.items():\n",
    "        total += w * sc[k]\n",
    "    return total, sc  # returns composite and breakdown\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
